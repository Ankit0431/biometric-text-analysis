---
tags:
- sentence-transformers
- sentence-similarity
- feature-extraction
- dense
- generated_from_trainer
- dataset_size:40
- loss:TripletLoss
base_model: sentence-transformers/paraphrase-MiniLM-L6-v2
widget:
- source_sentence: Previous literature has established a statistically significant
    correlation between the primary variables of interest; however, the underlying
    causal mechanisms and mediating pathways remain poorly understood and inadequately
    theorized in the existing scholarly discourse. Our current study aims to address
    this critical gap in the literature by systematically examining the underlying
    psychological and social processes through carefully controlled experimental manipulation
    and longitudinal observation. The research design incorporates multiple control
    conditions and employs sophisticated statistical modeling techniques to isolate
    the effects of specific variables while accounting for potential confounding factors
    that have been identified in previous research.
  sentences:
  - I believe that artificial intelligence will fundamentally revolutionize the way
    we approach software development and engineering practices. The integration of
    machine learning algorithms into traditional programming workflows presents both
    unprecedented opportunities and complex challenges that we must carefully consider
    from multiple perspectives. When designing AI-powered development tools, we need
    to balance automation with human oversight, ensuring that the technology enhances
    rather than replaces human creativity and problem-solving capabilities. The key
    is to create systems that augment developer productivity while maintaining code
    quality, security, and maintainability standards that are essential for long-term
    project success.
  - Previous literature has established a statistically significant correlation between
    the primary variables of interest; however, the underlying causal mechanisms and
    mediating pathways remain poorly understood and inadequately theorized in the
    existing scholarly discourse. Our current study aims to address this critical
    gap in the literature by systematically examining the underlying psychological
    and social processes through carefully controlled experimental manipulation and
    longitudinal observation. The research design incorporates multiple control conditions
    and employs sophisticated statistical modeling techniques to isolate the effects
    of specific variables while accounting for potential confounding factors that
    have been identified in previous research.
  - The research methodology employed in this comprehensive study follows a carefully
    designed mixed-methods approach, systematically combining quantitative statistical
    analysis with detailed qualitative observational techniques and ethnographic fieldwork.
    This methodological triangulation approach allows for a significantly more comprehensive
    and nuanced understanding of the complex social phenomenon under investigation,
    enabling researchers to capture both the measurable aspects and the subjective
    experiences of participants. The integration of multiple data collection methods
    helps to mitigate the inherent limitations of any single approach while providing
    robust validation of findings through cross-verification of results obtained through
    different methodological lenses.
- source_sentence: Previous literature has established a statistically significant
    correlation between the primary variables of interest; however, the underlying
    causal mechanisms and mediating pathways remain poorly understood and inadequately
    theorized in the existing scholarly discourse. Our current study aims to address
    this critical gap in the literature by systematically examining the underlying
    psychological and social processes through carefully controlled experimental manipulation
    and longitudinal observation. The research design incorporates multiple control
    conditions and employs sophisticated statistical modeling techniques to isolate
    the effects of specific variables while accounting for potential confounding factors
    that have been identified in previous research.
  sentences:
  - Previous literature has established a statistically significant correlation between
    the primary variables of interest; however, the underlying causal mechanisms and
    mediating pathways remain poorly understood and inadequately theorized in the
    existing scholarly discourse. Our current study aims to address this critical
    gap in the literature by systematically examining the underlying psychological
    and social processes through carefully controlled experimental manipulation and
    longitudinal observation. The research design incorporates multiple control conditions
    and employs sophisticated statistical modeling techniques to isolate the effects
    of specific variables while accounting for potential confounding factors that
    have been identified in previous research.
  - The findings emerging from this investigation suggest that conventional wisdom
    and widely accepted assumptions regarding this topic may need to be fundamentally
    reconsidered and potentially revised in light of the new evidence presented here.
    The empirical results consistently point toward alternative theoretical explanations
    that warrant extensive further investigation and systematic validation through
    carefully designed replication studies across different populations and contexts.
    These unexpected findings have significant implications for current practice and
    policy recommendations in the field.
  - I believe that artificial intelligence will fundamentally revolutionize the way
    we approach software development and engineering practices. The integration of
    machine learning algorithms into traditional programming workflows presents both
    unprecedented opportunities and complex challenges that we must carefully consider
    from multiple perspectives. When designing AI-powered development tools, we need
    to balance automation with human oversight, ensuring that the technology enhances
    rather than replaces human creativity and problem-solving capabilities. The key
    is to create systems that augment developer productivity while maintaining code
    quality, security, and maintainability standards that are essential for long-term
    project success.
- source_sentence: The theoretical framework developed and presented in this paper
    builds substantially upon well-established foundational principles from cognitive
    psychology and social learning theory while simultaneously introducing several
    novel conceptual frameworks that significantly extend the current understanding
    of the domain. These theoretical contributions have far-reaching implications
    for both academic theory development and practical applications in educational
    and therapeutic settings. The proposed model synthesizes insights from diverse
    disciplines including neuroscience, developmental psychology, and social anthropology
    to provide a more holistic understanding of the phenomenon under investigation.
  sentences:
  - Previous literature has established a statistically significant correlation between
    the primary variables of interest; however, the underlying causal mechanisms and
    mediating pathways remain poorly understood and inadequately theorized in the
    existing scholarly discourse. Our current study aims to address this critical
    gap in the literature by systematically examining the underlying psychological
    and social processes through carefully controlled experimental manipulation and
    longitudinal observation. The research design incorporates multiple control conditions
    and employs sophisticated statistical modeling techniques to isolate the effects
    of specific variables while accounting for potential confounding factors that
    have been identified in previous research.
  - The theoretical framework developed and presented in this paper builds substantially
    upon well-established foundational principles from cognitive psychology and social
    learning theory while simultaneously introducing several novel conceptual frameworks
    that significantly extend the current understanding of the domain. These theoretical
    contributions have far-reaching implications for both academic theory development
    and practical applications in educational and therapeutic settings. The proposed
    model synthesizes insights from diverse disciplines including neuroscience, developmental
    psychology, and social anthropology to provide a more holistic understanding of
    the phenomenon under investigation.
  - Data collection procedures were meticulously designed and rigorously tested to
    minimize systematic bias and ensure truly representative sampling across diverse
    demographic groups and geographic regions. The comprehensive protocol was thoroughly
    reviewed and formally approved by the institutional review board to ensure strict
    ethical compliance throughout all phases of the research process. Particular attention
    was paid to informed consent procedures, participant confidentiality protections,
    and the development of culturally sensitive data collection instruments that could
    be appropriately adapted for use with participants from various linguistic and
    cultural backgrounds.
- source_sentence: Data collection procedures were meticulously designed and rigorously
    tested to minimize systematic bias and ensure truly representative sampling across
    diverse demographic groups and geographic regions. The comprehensive protocol
    was thoroughly reviewed and formally approved by the institutional review board
    to ensure strict ethical compliance throughout all phases of the research process.
    Particular attention was paid to informed consent procedures, participant confidentiality
    protections, and the development of culturally sensitive data collection instruments
    that could be appropriately adapted for use with participants from various linguistic
    and cultural backgrounds.
  sentences:
  - When implementing distributed systems at scale, it's absolutely crucial to consider
    fault tolerance, data consistency, and network partitioning issues from the very
    beginning of the design process. The CAP theorem reminds us that we can't have
    all three guarantees simultaneously in a distributed environment, so we must make
    informed trade-offs based on our specific business requirements and technical
    constraints. I've found that understanding these fundamental principles early
    in the architecture phase saves countless hours of debugging and redesign later
    in the development lifecycle. The choice between consistency and availability
    often depends on the specific use case and business impact of temporary data inconsistencies.
  - The research methodology employed in this comprehensive study follows a carefully
    designed mixed-methods approach, systematically combining quantitative statistical
    analysis with detailed qualitative observational techniques and ethnographic fieldwork.
    This methodological triangulation approach allows for a significantly more comprehensive
    and nuanced understanding of the complex social phenomenon under investigation,
    enabling researchers to capture both the measurable aspects and the subjective
    experiences of participants. The integration of multiple data collection methods
    helps to mitigate the inherent limitations of any single approach while providing
    robust validation of findings through cross-verification of results obtained through
    different methodological lenses.
  - Data collection procedures were meticulously designed and rigorously tested to
    minimize systematic bias and ensure truly representative sampling across diverse
    demographic groups and geographic regions. The comprehensive protocol was thoroughly
    reviewed and formally approved by the institutional review board to ensure strict
    ethical compliance throughout all phases of the research process. Particular attention
    was paid to informed consent procedures, participant confidentiality protections,
    and the development of culturally sensitive data collection instruments that could
    be appropriately adapted for use with participants from various linguistic and
    cultural backgrounds.
- source_sentence: The theoretical framework developed and presented in this paper
    builds substantially upon well-established foundational principles from cognitive
    psychology and social learning theory while simultaneously introducing several
    novel conceptual frameworks that significantly extend the current understanding
    of the domain. These theoretical contributions have far-reaching implications
    for both academic theory development and practical applications in educational
    and therapeutic settings. The proposed model synthesizes insights from diverse
    disciplines including neuroscience, developmental psychology, and social anthropology
    to provide a more holistic understanding of the phenomenon under investigation.
  sentences:
  - The findings emerging from this investigation suggest that conventional wisdom
    and widely accepted assumptions regarding this topic may need to be fundamentally
    reconsidered and potentially revised in light of the new evidence presented here.
    The empirical results consistently point toward alternative theoretical explanations
    that warrant extensive further investigation and systematic validation through
    carefully designed replication studies across different populations and contexts.
    These unexpected findings have significant implications for current practice and
    policy recommendations in the field.
  - The research methodology employed in this comprehensive study follows a carefully
    designed mixed-methods approach, systematically combining quantitative statistical
    analysis with detailed qualitative observational techniques and ethnographic fieldwork.
    This methodological triangulation approach allows for a significantly more comprehensive
    and nuanced understanding of the complex social phenomenon under investigation,
    enabling researchers to capture both the measurable aspects and the subjective
    experiences of participants. The integration of multiple data collection methods
    helps to mitigate the inherent limitations of any single approach while providing
    robust validation of findings through cross-verification of results obtained through
    different methodological lenses.
  - I believe that artificial intelligence will fundamentally revolutionize the way
    we approach software development and engineering practices. The integration of
    machine learning algorithms into traditional programming workflows presents both
    unprecedented opportunities and complex challenges that we must carefully consider
    from multiple perspectives. When designing AI-powered development tools, we need
    to balance automation with human oversight, ensuring that the technology enhances
    rather than replaces human creativity and problem-solving capabilities. The key
    is to create systems that augment developer productivity while maintaining code
    quality, security, and maintainability standards that are essential for long-term
    project success.
pipeline_tag: sentence-similarity
library_name: sentence-transformers
metrics:
- cosine_accuracy
model-index:
- name: SentenceTransformer based on sentence-transformers/paraphrase-MiniLM-L6-v2
  results:
  - task:
      type: triplet
      name: Triplet
    dataset:
      name: triplet evaluation
      type: triplet_evaluation
    metrics:
    - type: cosine_accuracy
      value: 0.699999988079071
      name: Cosine Accuracy
---

# SentenceTransformer based on sentence-transformers/paraphrase-MiniLM-L6-v2

This is a [sentence-transformers](https://www.SBERT.net) model finetuned from [sentence-transformers/paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2). It maps sentences & paragraphs to a 384-dimensional dense vector space and can be used for semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more.

## Model Details

### Model Description
- **Model Type:** Sentence Transformer
- **Base model:** [sentence-transformers/paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2) <!-- at revision c9a2bfebc254878aee8c3aca9e6844d5bbb102d1 -->
- **Maximum Sequence Length:** 128 tokens
- **Output Dimensionality:** 384 dimensions
- **Similarity Function:** Cosine Similarity
<!-- - **Training Dataset:** Unknown -->
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Documentation:** [Sentence Transformers Documentation](https://sbert.net)
- **Repository:** [Sentence Transformers on GitHub](https://github.com/huggingface/sentence-transformers)
- **Hugging Face:** [Sentence Transformers on Hugging Face](https://huggingface.co/models?library=sentence-transformers)

### Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
```

## Usage

### Direct Usage (Sentence Transformers)

First install the Sentence Transformers library:

```bash
pip install -U sentence-transformers
```

Then you can load this model and run inference.
```python
from sentence_transformers import SentenceTransformer

# Download from the 🤗 Hub
model = SentenceTransformer("sentence_transformers_model_id")
# Run inference
sentences = [
    'The theoretical framework developed and presented in this paper builds substantially upon well-established foundational principles from cognitive psychology and social learning theory while simultaneously introducing several novel conceptual frameworks that significantly extend the current understanding of the domain. These theoretical contributions have far-reaching implications for both academic theory development and practical applications in educational and therapeutic settings. The proposed model synthesizes insights from diverse disciplines including neuroscience, developmental psychology, and social anthropology to provide a more holistic understanding of the phenomenon under investigation.',
    'The research methodology employed in this comprehensive study follows a carefully designed mixed-methods approach, systematically combining quantitative statistical analysis with detailed qualitative observational techniques and ethnographic fieldwork. This methodological triangulation approach allows for a significantly more comprehensive and nuanced understanding of the complex social phenomenon under investigation, enabling researchers to capture both the measurable aspects and the subjective experiences of participants. The integration of multiple data collection methods helps to mitigate the inherent limitations of any single approach while providing robust validation of findings through cross-verification of results obtained through different methodological lenses.',
    'I believe that artificial intelligence will fundamentally revolutionize the way we approach software development and engineering practices. The integration of machine learning algorithms into traditional programming workflows presents both unprecedented opportunities and complex challenges that we must carefully consider from multiple perspectives. When designing AI-powered development tools, we need to balance automation with human oversight, ensuring that the technology enhances rather than replaces human creativity and problem-solving capabilities. The key is to create systems that augment developer productivity while maintaining code quality, security, and maintainability standards that are essential for long-term project success.',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 384]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities)
# tensor([[1.0000, 0.4078, 0.3823],
#         [0.4078, 1.0000, 0.2418],
#         [0.3823, 0.2418, 1.0000]])
```

<!--
### Direct Usage (Transformers)

<details><summary>Click to see the direct usage in Transformers</summary>

</details>
-->

<!--
### Downstream Usage (Sentence Transformers)

You can finetune this model on your own dataset.

<details><summary>Click to expand</summary>

</details>
-->

<!--
### Out-of-Scope Use

*List how the model may foreseeably be misused and address what users ought not to do with the model.*
-->

## Evaluation

### Metrics

#### Triplet

* Dataset: `triplet_evaluation`
* Evaluated with [<code>TripletEvaluator</code>](https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#sentence_transformers.evaluation.TripletEvaluator)

| Metric              | Value   |
|:--------------------|:--------|
| **cosine_accuracy** | **0.7** |

<!--
## Bias, Risks and Limitations

*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*
-->

<!--
### Recommendations

*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*
-->

## Training Details

### Training Dataset

#### Unnamed Dataset

* Size: 40 training samples
* Columns: <code>sentence_0</code>, <code>sentence_1</code>, and <code>sentence_2</code>
* Approximate statistics based on the first 40 samples:
  |         | sentence_0                                                                           | sentence_1                                                                           | sentence_2                                                                           |
  |:--------|:-------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------|
  | type    | string                                                                               | string                                                                               | string                                                                               |
  | details | <ul><li>min: 84 tokens</li><li>mean: 109.85 tokens</li><li>max: 128 tokens</li></ul> | <ul><li>min: 84 tokens</li><li>mean: 109.67 tokens</li><li>max: 128 tokens</li></ul> | <ul><li>min: 84 tokens</li><li>mean: 106.03 tokens</li><li>max: 125 tokens</li></ul> |
* Samples:
  | sentence_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | sentence_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | sentence_2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
  |:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | <code>Data collection procedures were meticulously designed and rigorously tested to minimize systematic bias and ensure truly representative sampling across diverse demographic groups and geographic regions. The comprehensive protocol was thoroughly reviewed and formally approved by the institutional review board to ensure strict ethical compliance throughout all phases of the research process. Particular attention was paid to informed consent procedures, participant confidentiality protections, and the development of culturally sensitive data collection instruments that could be appropriately adapted for use with participants from various linguistic and cultural backgrounds.</code>                                                                              | <code>The findings emerging from this investigation suggest that conventional wisdom and widely accepted assumptions regarding this topic may need to be fundamentally reconsidered and potentially revised in light of the new evidence presented here. The empirical results consistently point toward alternative theoretical explanations that warrant extensive further investigation and systematic validation through carefully designed replication studies across different populations and contexts. These unexpected findings have significant implications for current practice and policy recommendations in the field.</code>                                                                                                                                | <code>I believe that artificial intelligence will fundamentally revolutionize the way we approach software development and engineering practices. The integration of machine learning algorithms into traditional programming workflows presents both unprecedented opportunities and complex challenges that we must carefully consider from multiple perspectives. When designing AI-powered development tools, we need to balance automation with human oversight, ensuring that the technology enhances rather than replaces human creativity and problem-solving capabilities. The key is to create systems that augment developer productivity while maintaining code quality, security, and maintainability standards that are essential for long-term project success.</code>                         |
  | <code>Code review processes are absolutely essential for maintaining software quality and knowledge sharing across development teams. I prefer to focus on architectural decisions, design patterns, and potential edge cases rather than minor style issues that can be automatically handled by linting tools and code formatters. During reviews, I always look for opportunities to improve code readability, performance, and maintainability while ensuring that the implementation aligns with established coding standards and best practices. The most valuable reviews often involve discussions about alternative approaches and their trade-offs rather than simply checking for syntax errors or style violations.</code>                                                            | <code>When implementing distributed systems at scale, it's absolutely crucial to consider fault tolerance, data consistency, and network partitioning issues from the very beginning of the design process. The CAP theorem reminds us that we can't have all three guarantees simultaneously in a distributed environment, so we must make informed trade-offs based on our specific business requirements and technical constraints. I've found that understanding these fundamental principles early in the architecture phase saves countless hours of debugging and redesign later in the development lifecycle. The choice between consistency and availability often depends on the specific use case and business impact of temporary data inconsistencies.</code> | <code>The findings emerging from this investigation suggest that conventional wisdom and widely accepted assumptions regarding this topic may need to be fundamentally reconsidered and potentially revised in light of the new evidence presented here. The empirical results consistently point toward alternative theoretical explanations that warrant extensive further investigation and systematic validation through carefully designed replication studies across different populations and contexts. These unexpected findings have significant implications for current practice and policy recommendations in the field.</code>                                                                                                                                                                   |
  | <code>Microservices architecture offers significant scalability benefits but introduces substantial complexity in service coordination, monitoring, and deployment orchestration. The decision to adopt microservices should be based on careful consideration of team size, system requirements, operational capabilities, and the organization's ability to manage distributed systems effectively. I've observed that successful microservices implementations require strong DevOps practices, comprehensive monitoring solutions, and well-defined service boundaries that minimize inter-service dependencies. The transition from monolithic to microservices architecture should be gradual and driven by specific business needs rather than following technology trends blindly.</code> | <code>When implementing distributed systems at scale, it's absolutely crucial to consider fault tolerance, data consistency, and network partitioning issues from the very beginning of the design process. The CAP theorem reminds us that we can't have all three guarantees simultaneously in a distributed environment, so we must make informed trade-offs based on our specific business requirements and technical constraints. I've found that understanding these fundamental principles early in the architecture phase saves countless hours of debugging and redesign later in the development lifecycle. The choice between consistency and availability often depends on the specific use case and business impact of temporary data inconsistencies.</code> | <code>Previous literature has established a statistically significant correlation between the primary variables of interest; however, the underlying causal mechanisms and mediating pathways remain poorly understood and inadequately theorized in the existing scholarly discourse. Our current study aims to address this critical gap in the literature by systematically examining the underlying psychological and social processes through carefully controlled experimental manipulation and longitudinal observation. The research design incorporates multiple control conditions and employs sophisticated statistical modeling techniques to isolate the effects of specific variables while accounting for potential confounding factors that have been identified in previous research.</code> |
* Loss: [<code>TripletLoss</code>](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#tripletloss) with these parameters:
  ```json
  {
      "distance_metric": "TripletDistanceMetric.EUCLIDEAN",
      "triplet_margin": 5
  }
  ```

### Training Hyperparameters
#### Non-Default Hyperparameters

- `eval_strategy`: steps
- `num_train_epochs`: 1
- `multi_dataset_batch_sampler`: round_robin

#### All Hyperparameters
<details><summary>Click to expand</summary>

- `overwrite_output_dir`: False
- `do_predict`: False
- `eval_strategy`: steps
- `prediction_loss_only`: True
- `per_device_train_batch_size`: 8
- `per_device_eval_batch_size`: 8
- `per_gpu_train_batch_size`: None
- `per_gpu_eval_batch_size`: None
- `gradient_accumulation_steps`: 1
- `eval_accumulation_steps`: None
- `torch_empty_cache_steps`: None
- `learning_rate`: 5e-05
- `weight_decay`: 0.0
- `adam_beta1`: 0.9
- `adam_beta2`: 0.999
- `adam_epsilon`: 1e-08
- `max_grad_norm`: 1
- `num_train_epochs`: 1
- `max_steps`: -1
- `lr_scheduler_type`: linear
- `lr_scheduler_kwargs`: {}
- `warmup_ratio`: 0.0
- `warmup_steps`: 0
- `log_level`: passive
- `log_level_replica`: warning
- `log_on_each_node`: True
- `logging_nan_inf_filter`: True
- `save_safetensors`: True
- `save_on_each_node`: False
- `save_only_model`: False
- `restore_callback_states_from_checkpoint`: False
- `no_cuda`: False
- `use_cpu`: False
- `use_mps_device`: False
- `seed`: 42
- `data_seed`: None
- `jit_mode_eval`: False
- `bf16`: False
- `fp16`: False
- `fp16_opt_level`: O1
- `half_precision_backend`: auto
- `bf16_full_eval`: False
- `fp16_full_eval`: False
- `tf32`: None
- `local_rank`: 0
- `ddp_backend`: None
- `tpu_num_cores`: None
- `tpu_metrics_debug`: False
- `debug`: []
- `dataloader_drop_last`: False
- `dataloader_num_workers`: 0
- `dataloader_prefetch_factor`: None
- `past_index`: -1
- `disable_tqdm`: False
- `remove_unused_columns`: True
- `label_names`: None
- `load_best_model_at_end`: False
- `ignore_data_skip`: False
- `fsdp`: []
- `fsdp_min_num_params`: 0
- `fsdp_config`: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
- `fsdp_transformer_layer_cls_to_wrap`: None
- `accelerator_config`: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}
- `parallelism_config`: None
- `deepspeed`: None
- `label_smoothing_factor`: 0.0
- `optim`: adamw_torch_fused
- `optim_args`: None
- `adafactor`: False
- `group_by_length`: False
- `length_column_name`: length
- `project`: huggingface
- `trackio_space_id`: trackio
- `ddp_find_unused_parameters`: None
- `ddp_bucket_cap_mb`: None
- `ddp_broadcast_buffers`: False
- `dataloader_pin_memory`: True
- `dataloader_persistent_workers`: False
- `skip_memory_metrics`: True
- `use_legacy_prediction_loop`: False
- `push_to_hub`: False
- `resume_from_checkpoint`: None
- `hub_model_id`: None
- `hub_strategy`: every_save
- `hub_private_repo`: None
- `hub_always_push`: False
- `hub_revision`: None
- `gradient_checkpointing`: False
- `gradient_checkpointing_kwargs`: None
- `include_inputs_for_metrics`: False
- `include_for_metrics`: []
- `eval_do_concat_batches`: True
- `fp16_backend`: auto
- `push_to_hub_model_id`: None
- `push_to_hub_organization`: None
- `mp_parameters`: 
- `auto_find_batch_size`: False
- `full_determinism`: False
- `torchdynamo`: None
- `ray_scope`: last
- `ddp_timeout`: 1800
- `torch_compile`: False
- `torch_compile_backend`: None
- `torch_compile_mode`: None
- `include_tokens_per_second`: False
- `include_num_input_tokens_seen`: no
- `neftune_noise_alpha`: None
- `optim_target_modules`: None
- `batch_eval_metrics`: False
- `eval_on_start`: False
- `use_liger_kernel`: False
- `liger_kernel_config`: None
- `eval_use_gather_object`: False
- `average_tokens_across_devices`: True
- `prompts`: None
- `batch_sampler`: batch_sampler
- `multi_dataset_batch_sampler`: round_robin
- `router_mapping`: {}
- `learning_rate_mapping`: {}

</details>

### Training Logs
| Epoch | Step | triplet_evaluation_cosine_accuracy |
|:-----:|:----:|:----------------------------------:|
| 1.0   | 5    | 0.7000                             |


### Framework Versions
- Python: 3.12.2
- Sentence Transformers: 5.1.2
- Transformers: 4.57.1
- PyTorch: 2.9.0+cpu
- Accelerate: 1.11.0
- Datasets: 4.3.0
- Tokenizers: 0.22.1

## Citation

### BibTeX

#### Sentence Transformers
```bibtex
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
```

#### TripletLoss
```bibtex
@misc{hermans2017defense,
    title={In Defense of the Triplet Loss for Person Re-Identification},
    author={Alexander Hermans and Lucas Beyer and Bastian Leibe},
    year={2017},
    eprint={1703.07737},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```

<!--
## Glossary

*Clearly define terms in order to be accessible across audiences.*
-->

<!--
## Model Card Authors

*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*
-->

<!--
## Model Card Contact

*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*
-->